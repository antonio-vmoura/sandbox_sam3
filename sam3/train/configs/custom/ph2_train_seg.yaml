  # @package _global_
  defaults:
    - _self_

  # ============================================================================
  # Paths Configuration
  # ============================================================================
  paths:
    root_dir: /workspace
    ph2_root: ${paths.root_dir}/data/ph2
    experiment_log_dir: ${paths.root_dir}/logs/ph2_train_seg_500
    bpe_path: ${paths.root_dir}/sam3/assets/bpe_simple_vocab_16e6.txt.gz

  # ============================================================================
  # PH2 Dataset Configuration
  # ============================================================================
  ph2_config:
    num_images: null 
    train_img_dir: ${paths.ph2_root}/train/
    train_ann_file: ${paths.ph2_root}/train/_annotations.coco.json
    val_img_dir: ${paths.ph2_root}/test/
    val_ann_file: ${paths.ph2_root}/test/_annotations.coco.json

    # Training transforms
    train_transforms:
      - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
        transforms:
          - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
            query_filter:
              _target_: sam3.train.transforms.filter_query_transforms.FilterCrowds
          - _target_: sam3.train.transforms.segmentation.DecodeRle
          - _target_: sam3.train.transforms.point_sampling.RandomizeInputBbox
            box_noise_std: 0.2  # Era 0.1. Aumentar força o modelo a ser mais robusto.
            box_noise_max: 50   # Era 20. Permite caixas mais "erradas" no treino.
          - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
            sizes:
              _target_: sam3.train.transforms.basic.get_random_resize_scales
              size: ${scratch.resolution}
              min_size: 480
              rounded: false
            max_size:
              _target_: sam3.train.transforms.basic.get_random_resize_max_size
              size: ${scratch.resolution}
            square: true
            consistent_transform: ${scratch.consistent_transform}
          - _target_: sam3.train.transforms.basic_for_api.PadToSizeAPI
            size: ${scratch.resolution}
            consistent_transform: ${scratch.consistent_transform}
          - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
          - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
            query_filter:
              _target_: sam3.train.transforms.filter_query_transforms.FilterEmptyTargets
          - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
            mean: ${scratch.train_norm_mean}
            std: ${scratch.train_norm_std}
      - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
        query_filter:
          _target_: sam3.train.transforms.filter_query_transforms.FilterFindQueriesWithTooManyOut
          max_num_objects: ${scratch.max_ann_per_img}

    # Validation transforms
    val_transforms:
      - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
        transforms:
          - _target_: sam3.train.transforms.segmentation.DecodeRle
          - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
            sizes: ${scratch.resolution}
            max_size:
              _target_: sam3.train.transforms.basic.get_random_resize_max_size
              size: ${scratch.resolution}
            square: true
            consistent_transform: False
          - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
          - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
            mean: ${scratch.train_norm_mean}
            std: ${scratch.train_norm_std}

    # Loss config
    loss:
      _target_: sam3.train.loss.sam3_loss.Sam3LossWrapper
      matcher: ${scratch.matcher}
      o2m_weight: 2.0
      o2m_matcher:
        _target_: sam3.train.matcher.BinaryOneToManyMatcher
        alpha: 0.3
        threshold: 0.4
        topk: 4
      use_o2m_matcher_on_o2m_aux: false
      loss_fns_find:
        # Loss Boxes
        - _target_: sam3.train.loss.loss_fns.Boxes
          weight_dict:
            loss_bbox: 5.0
            loss_giou: 2.0
        # Loss Classification
        - _target_: sam3.train.loss.loss_fns.IABCEMdetr
          weak_loss: False
          weight_dict:
            loss_ce: 20.0
            presence_loss: 20.0
          pos_weight: 10.0
          alpha: 0.25
          gamma: 2
          use_presence: True
          pos_focal: false
          pad_n_queries: 200
          pad_scale_pos: 1.0
        # Loss Masks (Segmentação)
        - _target_: sam3.train.loss.loss_fns.Masks
          focal_alpha: 0.25
          focal_gamma: 2.0
          weight_dict:
            loss_mask: 5.0
            loss_dice: 5.0
          compute_aux: false
        # REMOVIDA: Loss IoU que causava erro de importação.
        # Ao usar 1 GPU, o erro de "unused parameters" não ocorrerá.

      loss_fn_semantic_seg: null
      scale_by_find_batch_size: ${scratch.scale_by_find_batch_size}

  # ============================================================================
  # Scratch Configuration
  # ============================================================================
  scratch:
    enable_segmentation: True
    
    d_model: 256
    pos_embed:
      _target_: sam3.model.position_encoding.PositionEmbeddingSine
      num_pos_feats: ${scratch.d_model}
      normalize: true
      scale: null
      temperature: 10000

    use_presence_eval: True
    original_box_postprocessor:
      _target_: sam3.eval.postprocessors.PostProcessImage
      max_dets_per_img: -1
      use_original_ids: true
      use_original_sizes_box: true
      use_presence: ${scratch.use_presence_eval}
    
    mask_postprocessor:
      _target_: sam3.eval.postprocessors.PostProcessImage
      max_dets_per_img: 100
      iou_type: "segm"
      use_original_ids: false
      use_original_sizes_box: true
      use_original_sizes_mask: true
      detection_threshold: 0.3
      use_presence: ${scratch.use_presence_eval}

    matcher:
      _target_: sam3.train.matcher.BinaryHungarianMatcherV2
      focal: true
      cost_class: 2.0
      cost_bbox: 5.0
      cost_giou: 2.0
      alpha: 0.25
      gamma: 2
      stable: False
    scale_by_find_batch_size: True

    resolution: 1008
    consistent_transform: False
    max_ann_per_img: 200

    train_norm_mean: [0.5, 0.5, 0.5]
    train_norm_std: [0.5, 0.5, 0.5]
    val_norm_mean: [0.5, 0.5, 0.5]
    val_norm_std: [0.5, 0.5, 0.5]

    # Workers
    num_train_workers: 2 #4 #8
    num_val_workers: 4
    max_data_epochs: 500
    target_epoch_size: 1500
    hybrid_repeats: 1
    context_length: 2
    gather_pred_via_filesys: false

    lr_scale: 0.1
    lr_transformer: ${times:1e-4,${scratch.lr_scale}}
    lr_vision_backbone: 0.0
    lr_language_backbone: 0.0
    lrd_vision_backbone: 1.0
    wd: 0.1
    scheduler_timescale: 20
    scheduler_warmup: 20
    scheduler_cooldown: 20

    val_batch_size: 2
    collate_fn_val:
      _target_: sam3.train.data.collator.collate_fn_api
      _partial_: true
      repeats: ${scratch.hybrid_repeats}
      dict_key: ph2_eval
      with_seg_masks: ${scratch.enable_segmentation}

    gradient_accumulation_steps: 8 #1
    train_batch_size: 1 #4
    collate_fn:
      _target_: sam3.train.data.collator.collate_fn_api
      _partial_: true
      repeats: ${scratch.hybrid_repeats}
      dict_key: all
      with_seg_masks: ${scratch.enable_segmentation}

  # ============================================================================
  # Trainer Configuration
  # ============================================================================
  trainer:
    _target_: sam3.train.trainer.Trainer
    skip_saving_ckpts: false
    empty_gpu_mem_cache_after_eval: True
    skip_first_val: False
    max_epochs: ${scratch.max_data_epochs}
    accelerator: cuda
    seed_value: 123
    val_epoch_freq: 5
    mode: train
    gradient_accumulation_steps: ${scratch.gradient_accumulation_steps}

    distributed:
      backend: nccl
      find_unused_parameters: True
      gradient_as_bucket_view: True

    loss:
      all: ${ph2_config.loss}
      default:
        _target_: sam3.train.loss.sam3_loss.DummyLoss

    data:
      train:
        _target_: sam3.train.data.torch_dataset.TorchDataset
        dataset:
          _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
          limit_ids: ${ph2_config.num_images}
          transforms: ${ph2_config.train_transforms}
          load_segmentation: ${scratch.enable_segmentation}
          max_ann_per_img: 500000
          multiplier: 1
          max_train_queries: 50000
          max_val_queries: 50000
          training: true
          use_caching: False
          img_folder: ${ph2_config.train_img_dir}
          ann_file: ${ph2_config.train_ann_file}
          coco_json_loader:
            _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
            prompts: null
            _partial_: true

        shuffle: True
        batch_size: ${scratch.train_batch_size}
        num_workers: ${scratch.num_train_workers}
        pin_memory: True
        drop_last: True
        collate_fn: ${scratch.collate_fn}

      val:
        _target_: sam3.train.data.torch_dataset.TorchDataset
        dataset:
          _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
          load_segmentation: ${scratch.enable_segmentation}
          coco_json_loader:
            _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
            include_negatives: true
            category_chunk_size: 2
            _partial_: true
          img_folder: ${ph2_config.val_img_dir}
          ann_file: ${ph2_config.val_ann_file}
          transforms: ${ph2_config.val_transforms}
          max_ann_per_img: 100000
          multiplier: 1
          training: false

        shuffle: False
        batch_size: ${scratch.val_batch_size}
        num_workers: ${scratch.num_val_workers}
        pin_memory: True
        drop_last: False
        collate_fn: ${scratch.collate_fn_val}

    model:
      _target_: sam3.model_builder.build_sam3_image_model
      bpe_path: ${paths.bpe_path}
      device: cpus
      eval_mode: false
      enable_segmentation: ${scratch.enable_segmentation}

    meters:
      val:
        ph2_eval:
          detection:
            _target_: sam3.eval.coco_writer.PredictionDumper
            iou_type: "segm"
            dump_dir: ${paths.experiment_log_dir}/dumps/ph2
            merge_predictions: True
            postprocessor: ${scratch.mask_postprocessor}
            gather_pred_via_filesys: ${scratch.gather_pred_via_filesys}
            maxdets: 100
            pred_file_evaluators:
              - _target_: sam3.eval.coco_eval_offline.CocoEvaluatorOfflineWithPredFileEvaluators
                gt_path: ${ph2_config.val_ann_file}
                tide: False
                iou_type: "bbox"
              - _target_: sam3.eval.coco_eval_offline.CocoEvaluatorOfflineWithPredFileEvaluators
                gt_path: ${ph2_config.val_ann_file}
                tide: False
                iou_type: "segm"

    optim:
      amp:
        enabled: True
        amp_dtype: float16

      optimizer:
        _target_: torch.optim.AdamW

      gradient_clip:
        _target_: sam3.train.optim.optimizer.GradientClipper
        max_norm: 0.1
        norm_type: 2

      param_group_modifiers:
        - _target_: sam3.train.optim.optimizer.layer_decay_param_modifier
          _partial_: True
          layer_decay_value: ${scratch.lrd_vision_backbone}
          apply_to: 'backbone.vision_backbone.trunk'
          overrides:
            - pattern: '*pos_embed*'
              value: 1.0

      options:
        lr:
          - scheduler:
              _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
              base_lr: ${scratch.lr_transformer}
              timescale: ${scratch.scheduler_timescale}
              warmup_steps: ${scratch.scheduler_warmup}
              cooldown_steps: ${scratch.scheduler_cooldown}
          - scheduler:
              _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
              base_lr: ${scratch.lr_vision_backbone}
              timescale: ${scratch.scheduler_timescale}
              warmup_steps: ${scratch.scheduler_warmup}
              cooldown_steps: ${scratch.scheduler_cooldown}
            param_names:
              - 'backbone.vision_backbone.*'
          - scheduler:
              _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
              base_lr: ${scratch.lr_language_backbone}
              timescale: ${scratch.scheduler_timescale}
              warmup_steps: ${scratch.scheduler_warmup}
              cooldown_steps: ${scratch.scheduler_cooldown}
            param_names:
              - 'backbone.language_backbone.*'

        weight_decay:
          - scheduler:
              _target_: fvcore.common.param_scheduler.ConstantParamScheduler
              value: ${scratch.wd}
          - scheduler:
              _target_: fvcore.common.param_scheduler.ConstantParamScheduler
              value: 0.0
            param_names:
              - '*bias*'
            module_cls_names: ['torch.nn.LayerNorm']

    checkpoint:
      save_dir: ${paths.experiment_log_dir}/checkpoints
      save_freq: 100

    logging:
      tensorboard_writer:
        _target_: sam3.train.utils.logger.make_tensorboard_logger
        log_dir: ${paths.experiment_log_dir}/tensorboard
        flush_secs: 120
        should_log: True
      wandb_writer: null
      log_dir: ${paths.experiment_log_dir}
      log_freq: 10

  launcher:
    num_nodes: 1
    gpus_per_node: 1 # [IMPORTANTE] Força 1 GPU apenas
    experiment_log_dir: ${paths.experiment_log_dir}
    multiprocessing_context: forkserver

  submitit:
    account: null
    partition: null
    qos: null
    timeout_hour: 72
    use_cluster: True
    cpus_per_task: 10
    port_range: [10000, 65000]
    constraint: null
    job_array:
      num_tasks: 1
      task_index: 0